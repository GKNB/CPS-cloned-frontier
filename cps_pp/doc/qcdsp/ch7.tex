\chapter{Single Processor Optimisation I -- Using CRAM}
\section{Introduction}
The greatest performance gains on the QCDSP can be made through
judicious use of the fast on--chip RAM that is built onto the 
processor and through the circular buffer.

The on--chip RAM, referred to from now on as CRAM is 2Kwords
worth of memory that can be immediately accessed
by the DSP processor. (It has a memory latency of 0 cycles).
 
The circular buffer can be thought of as another level of fast
memory. It can hold 32Kwords and deliver them to the processor
with a latency of a single cycle after some initial setup overhead.

Apart from these features, the DSP itself can overlap one floating
point addition with one floating point multiplication. This however
requires assembly coding of routines. 

One can take advantage of the CRAM and the circular buffer
from within C++ at the expense of knowing some magic numbers to set
the circular buffer modes. However using the CRAM requires the 
technique of ``overlay programming''.

\subsection{What this chapter covers}
In this chapter we wish to explain the process of using the CRAM.
We will do this in three stages. Firstly, we will construct a 
simple SU(3) matrix-vector multiplication routine and time it.

We will then explain how to relocate the C++ routine into the fast
CRAM, and time the resulting performance.

Finally, we will give an assembler optimised version of the same
routine and locate it into CRAM. At each stage, we should see the
number of clock cycles needed to perform the routine decrease\footnote{We will
ignore setup costs, although they are important for the case of a single
matrix vector multiply, they will become negligible when the operation
has to be performed for many matrices}. 

\subsection{What this chapter does not cover}
We do not cover the following:
\begin{itemize}
\item
DSP Architecture and Assembly language -- see the following:
\begin{description}
\item{{\bf TMS320C3x User's Guide}: \ } \\
\ {\tt http://www-s.ti.com/sc/psheets/spru031e/spru031e.pdf}
\item{{\bf TMS320C3x/C4x Assembly Language Tools User's Guide}: \ } \\
\ {\tt 
http://www-s.ti.com/sc/psheets/spru035c/spru035c.pdf}. NOTE this site
contains details of the Texas Instruments assembler and linker, not the 
Tartan Linker described in the last chapter.
\item{{\bf TMS320C3x General-purpose applications User Guide}: \ } \\
 {\tt 
http://www-s.ti.com/sc/psheets/spru194/spru194.pdf}
\end{description}
\item
Use of the Circular Buffer. See future addenda/re-releases of this 
document.
\end{itemize}

\section{Overlay Programming and the Linker Control File}
Overlay programming harks back to the days when computers had a limited
amount of memory and kept a lot of their code either in memory
that was too slow to access or somewhere else. The premise of the method
was that when a piece of code was not actually executed, it could be 
overwritten by another piece which could then be run. Designing a program so
that it split neatly into sets of overlays was a magic artform.

Nowadays of course workstations have effectively unlimited amounts of memory
and virtual memory management systems in operating systems take care
of paging memory and swapping memory out to disk (a kind of automatic
overlaying process). 

In embedded systems however overlay programming is still common and in
fact for the QCDSP it is necessary. The idea is that the overlays are
stored in the slow DRAM, but the linker resolves all the addresses in them
as if they were in the CRAM. Before use, a user copies the routines from 
DRAM into the CRAM and calls them there. 

\subsection{Virtual Addresses and the Linker Control File}\label{s:ModLCF}
In the last chapter we mentioned that the {\tt ALLOCATE} statements in 
a linker control file refer to the allocation of {\em virtual addresses}, 
but it just so happens that by default the virtual addresses and physical
addresses are the same. Now our CRAM is {\em memory mapped} into the 
the DSP address space. The lower part  of the CRAM contain interrupt
and status register areas so effectively from our point of view, the 
lowest address we can use to access the CRAM is 0x809800.

Hence routines that use the CRAM must be told that their (virtual) addresses
begin at 0x809800 or higher. We can do this with an {\tt ALLOCATE}
statement in the linker control file. The following {\tt ALLOCATE} statement
defines an overlay called {\tt mvmult\_overlay} (for a matrix vector multiply
routine) which will take relocatable object code and resolve it as if it
began at address 0x809800:
\begin{verbatim}
ALLOCATE "mvmult_overlay" kind = code image (
        origin = 0x809800 define "_mvmult_dest"
        kind = code module = matvecmult
);
\end{verbatim}

The {\tt ALLOCATE} statement defines a linker section called {\tt
mvmult\_overlay} containing code. The addresses in this linker section
will start from {\tt 0x809800} (the {\tt origin}) statement and the
linker symbol {\tt \_mvmult\_dest} has been defined to contain this
address (the {\tt define} statement). This symbol will be visible from
our C++ programs (and the leading underscore is important). The {\tt
kind} statement defines that the section will contain code, and the
{\tt module} command means that the code to be resolved lives in the
{\tt matvecmult} module which in this case means that the object code
for this section will be in the {\bf matvecmult.tof} file or any
library containing the modules from the {\bf matvecmult.tof} file.

So far so good. The address space of the {\tt matvecmult} module will
begin at 0x809800, however we do not want the code to be linked here.
We want the actual code section to be in the DRAM. Then, we could
copy it to 0x80980 before execution. We can't link it to this address
because the loader program (that loads our programs to the QCDSP nodes)
can only load to addresses in the DRAM which has an upper limit of 0x07FFFF.

Hence we have to tell the linker control file that our virtual and 
physical memory addresses are no longer the same and specify the order
in which linker sections should be laid out in physical memory. This 
can be done by the {\tt physical} statement just before the end of our
linker control file. 

Consider the following {\tt physical} definition:
\begin{verbatim}
PHYSICAL ( 
   origin = 0x1000
   section = ".bss"
   next section = ".data"
   next section = ".text"
   define "_mvmult_begin"
   next   section = "mvmult_overlay"
   define "_mvmult_end"
   next remaining
);
\end{verbatim}

This tells the linker that real (physical) memory starts at 0x1000
and that in the executable image, the {\tt .bss} section should start
at 0x1000, followed by the {\tt .data} and {\tt .text} sections. This
should immediately be followed by the code for the {\tt mvmult\_overlay}
section, however we wish to define linker symbols {\tt \_mvmult\_begin}
to point to the address where the overlay section will start and the 
{\tt \_mvmult\_end} symbol to point to the first address after it ends.
Finally, the {\tt next remaining} statement just tells the linker to 
put all the remaining sections to follow from the address {\tt \_mvmult\_end}.

The idea is that the code will be laid out in physical memory starting
at 0x1000. If we want to use the overlay we will have to copy the
contents of the DRAM from between the addresses of the {\tt
\_mvmult\_begin} symbol and the {\tt \_mvmult\_end} symbol to the
address of the {\tt \_mvmult\_dest} symbol. We can then call the 
subroutine and the code will start executing at the CRAM address because
that is what the linker set to be the origin of the routine.

To illustrate how the extra {\tt ALLOCATE} and {\tt PHYSICAL} statements
fit into the scheme of the usual linker control file, we now show the 
full file. You should be able to find it in {\tt /qcdsp/sfw/qos.5.3.3/example/optimise2/link.lcf}.
{\scriptsize
\begin{verbatim}
/*
// QCDSP Modified Default Linker Control File
// Taken from /usr/local/tartan/v2.1/etc/qcdsp_v5.3.3/link.lcf 
// and the physics system <phys_root>/mem/include/link_p2v.lcf
// Modifed By BJ
*/

link  

/*
// Display Banner
*/

banner "Tartan Linker for QCDSP version 5.3.3, modified 1/11/99 by RDM";
banner "Customised by BJ 4/29/2000";
banner "Memory size:  0x80000 (512 Kwords)";
banner "Stack  size:  0x10000 ( 64 Kwords)";
banner "Heap   size:  0x30000 (192 Kwords)";
banner "----------------------------------";
banner "Remaining  :  0x20000 (128 Kwords) for code and qloaded data";

/*
// These are standard
*/

resolve sections;                       // Eliminate unused sections
options romcopy;                        // init RAM variables from ROM

/*
// Configuration Constants
*/

define __STACK_SIZE     = 0x10000;      //  64K stack
define __SYSMEM_SIZE    = 0x30000;      // 192K heap

// These constants define bus control register values loaded at startup
define tc_PBCR_startup  = 0xF00;        // primary bus control value
// define tc_EBCR_startup       = 0x0;  // expansion bus control value

// These constants define ST, IE registers during initialization
define tc_ST_startup    = 0x2800;       // status register
define tc_IE_init       = 0x7FFF;       // interrupt mask
 
/*
// System Configuration
*/

define TDB_BREAKPOINT   = 0x66000000;   // breakpoint for Tartan debugger

control "*.ctl";                        // list of obj/lib files to link
                                        // *.ctl file built by Tartan shell

list "*.map";                           // default extension for link maps

space .stack, __STACK_SIZE;             // declare memory for program stack
space .sysmem, __SYSMEM_SIZE;           // declare memory for program heap

/*
// Explicit Modules
*/

use module = qcdsp_tcroot;              // general startup code
use module = tcrpc;                     // needed for Tartan debugger
use section = .cinit nowarn;            // link in .cinit tables

use kind = debug;                       // include debug information
use kind = dstring;                     // include debug strings
use kind = linenumber;                  // include debug line mapping

/*
// Define Memory Layout
*/

memory (
        limit = 0x80000;                //
        avoid = 0x0, 0x1000;            // 0x1000 - 0x7FFFF
);
 
/*
// Define Program Layout
*/

/*
// Create an overlay so that we can put matvecmult into
// On Chip RAM. 0x80980 is start of Memory mapped image
// of CRAM.

 */
allocate "mvmult_overlay" kind = code image (
        origin = 0x809800 define "_mvmult_dest"
        kind = code module = matvecmult
);

allocate ".bss" kind = data image (
                origin = 0x1000 kind=data
        );

allocate ".data" kind = constant image (
                kind=constant
        );

allocate ".text" kind = code image   (
                kind = code 
        );

allocate image (
        remaining
);

/*
// Debug Directives
//
// These commands are for debugger symbol information, and do
// not affect the size or location of the program
*/

allocate debug_directives image kind = debug
        (origin = 0 kind = debug);

allocate debug_strings image kind = dstring
        (origin = 0 kind = dstring);

allocate debug_source_location image kind = linenumber
        (origin = 0 kind = linenumber);


/* Specify physical memory  */
physical ( 
   origin = 0x1000
   section = ".bss"
   next section = ".data"
   next section = ".text"
   define "_mvmult_begin"
   next   section = "mvmult_overlay"
   define "_mvmult_end"
   next remaining
);

end link;
\end{verbatim}}

\subsection{Changes to C++ Files}
The symbols defined in the linker control files can be made apparent to 
the C++ source files using the {\tt extern "C"} statements. For example
to see the symbols defined in the linker control file above our
C++ program sould contain the lines
\begin{verbatim}
extern "C" void mvmult_dest();
extern "C" void mvmult_begin();
extern "C" void mvmuld_end();
\end{verbatim}

The reason for the {\tt extern "C"} statements, is to do with the 
C++ compiler. When you define a function like {\tt void foo(float)}
the C++ compiler encodes the name into some others string such as
{\tt \_foo\_\_XXXXX} for the linker symbol where {\tt XXXX} is some
code that signifies that this particular version of the {\tt foo} 
takes a single float argument. If you then define a {\tt void foo(int)}
(which you are perfectly allowed to do in C++) the compiler would mangle
this into some other compiler symbol, say {\tt \_foo\_\_YYYY}. The {\tt extern "C"} basically instructs the compiler to not do this encoding. Hence, after the
declarations above, if the C++ compiler encounters the {\tt mvmult\_dest}
it would not encode it but would straightforwardly translate it to
{\tt \_mvmult\_dest} which is the correct linker symbol that we defined
for it in the linker control file.

Likewise we must declare the actual {\tt matVecMult} function as {\tt extern "C"} otherwise the C++ compiler will mangle it to something else and the linker
will not find a module called {\tt matvecmult}. Instead it will find something
like {\tt \_matVecMult\_\_FPfN21}, which can lead to linking errors. I do 
this by defining a header file {\bf matvecmult.h} and {\tt \#include}-ing 
it both into the {\bf matvecmult.C} file where the subroutine is defined
(remember it has to be in a separate file to be a separate module) 
the and {\tt main.C} file where the routine is called. The header file
looks like this:
\begin{verbatim}
#ifndef MATVECMULT_H
#define MATVECMULT_H
extern "C" void matVecMult(float *, float *, float *);
#endif
\end{verbatim}
	
Why do the symbols need to be declared as void functions? Well in the 
linker control file we defined them effectively as entry points to functions.
These functions take no arguments in this example, but may in later ones.

\subsection{Copying the Code to the CRAM}
Once the linker control file is set up correctly and the linker
symbols are visible we simply need to write a subroutine to copy 
the {\tt matVecMult} subroutine  into the CRAM. This could be done with
a single {\tt memcpy} instruction, but despite the claims of the 
Tartan manual, I couldn't manage to find the library where {\tt memcpy}
lives. Consequentially I just wrote a loop to do the {\tt memcpy} which I
show below:
{\scriptsize
\begin{verbatim}
void loadMatVecMultIntoCRAM(void)
{
   unsigned int length = (unsigned int*)&mvmult_end
                        -(unsigned int*)&mvmult_begin;
	
   // I guess uip stands for unsigned integer pointer

   unsigned int * uip_src = (unsigned int *)&mvmult_begin;
   unsigned int * uip_dest = (unsigned int *)&mvmult_dest;

   printf("Copying MatVecMult Into CRAM\n");
   int i;
   for(i=0; i < length; i++) {
        *uip_dest++ = *uip_src++;
   }    
   printf("Done\n");
}
\end{verbatim}}

Note here the usage of the external symbols. The addresses of the 
symbols (without any calling parameters or trailing brackets) are 
used to get at the memory addresses at which they were defined in
the linker control file. The results are cast to unsigned integers. 

Let us now go through the process of optimising. We will follow the 
example above and deal with a single SU(3) matrix times 3-vector 
multiplication.

\section{Step One: Straight C++}
In this section, we shall write a basic vector and matrix class 
in file called {\bf matvec.h}, a routine to multiply the two together
in {\bf matvecmult.C} and finally a {\bf main.C} file where we
time the multiplication routines. There is also a file called {\bf 
defines.h} where we define a few convenient macros.

I present here the header files. Firstly {\bf defines.h}
{\scriptsize
\begin{verbatim}
#ifndef DEFINES_H
#define DEFINES_H

#define RE  0
#define IM  1
#define N_COMPLEX 2
#define N_COLOUR  3

#endif
\end{verbatim}}
secondly {\bf matvec.h} 
{\scriptsize
\begin{verbatim}
// ---------------------------
// matvec.h
// ---------------------------
#ifndef MATVEC_H
#define MATVEC_H

#include "defines.h"

// ----------------------------------------
// Quick and dirty Complex 3x3 matrix class
// Supports indexing and can get a
// pointer to the matrix class
// ----------------------------------------

class Matrix {
private:
  float data_[N_COLOUR * N_COLOUR * N_COMPLEX];
public:
  float & operator()(int cmpx, int col, int row) 
  {
        return( data_[ cmpx + N_COMPLEX*(col + N_COLOUR*row) ]  );
  }

  float* data() 
  {
        return &data_[0]; 
  }
};

// -----------------------------------------
// Quick and dirty complex 3 vector
// ------------------------------------------

class Vector {
private:
   float data_[N_COLOUR * N_COMPLEX];
public: 

   float & operator()(int cmpx, int row) 
   {
        return( data_[ cmpx + N_COMPLEX*row ] );
   }
 
   float * data()
   { 
        return &data_[0];
   }
}; 
#endif
\end{verbatim}}
and finally {\bf matvecmult.h}
{\scriptsize
\begin{verbatim}
#ifndef MATVECMULT_H
#define MATVECMULT_H
extern "C" void matVecMult(float *, float *, float *);
#endif
\end{verbatim}}

The corresponding C++ files are {\bf matvecmult.C}:
{\scriptsize
\begin{verbatim}
#include "matvecmult.h"
// Define some indexes into the Matrix
// For Loop Unrolling

// First Row (Row 0) Columnwise
#define RE00  0
#define IM00  1
#define RE10  2
#define IM10  3
#define RE20  4
#define IM20  5

// Second Row (Row 1) Columnwise
#define RE01  6
#define IM01  7
#define RE11  8
#define IM11  9 
#define RE21  10
#define IM21  11

// Third Row (Row 2) Columnwise
#define RE02  12
#define IM02  13
#define RE12  14
#define IM12  15
#define RE22  16
#define IM22  17


// Define Some indices into the vectors
#define RE0    0
#define IM0    1
#define RE1    2
#define IM1    3
#define RE2    4
#define IM2    5

void matVecMult(float *y, float *a, float *x)
{
        // First row

        y[RE0] = ( a[RE00]*x[RE0] - a[IM00]*x[IM0] )
                +( a[RE10]*x[RE1] - a[IM10]*x[IM1] )
                +( a[RE20]*x[RE2] - a[IM20]*x[IM2] );

        y[IM0] = ( a[RE00]*x[IM0] + a[IM00]*x[RE0] )
                +( a[RE10]*x[IM1] + a[IM10]*x[RE1] )
                +( a[RE20]*x[IM2] + a[IM20]*x[RE2] );

        // Second Row
        y[RE1] = ( a[RE01]*x[RE0] - a[IM01]*x[IM0] )
                +( a[RE11]*x[RE1] - a[IM11]*x[IM1] )
                +( a[RE21]*x[RE2] - a[IM21]*x[IM2] );

        y[IM1] = ( a[RE01]*x[IM0] + a[IM01]*x[RE0] )
                +( a[RE11]*x[IM1] + a[IM11]*x[RE1] )
                +( a[RE21]*x[IM2] + a[IM21]*x[RE2] );


        // Third Row
        y[RE2] = ( a[RE02]*x[RE0] - a[IM02]*x[IM0] )
                +( a[RE12]*x[RE1] - a[IM12]*x[IM1] )
                +( a[RE22]*x[RE2] - a[IM22]*x[IM2] );

        y[IM2] = ( a[RE02]*x[IM0] + a[IM02]*x[RE0] )
                +( a[RE12]*x[IM1] + a[IM12]*x[RE1] )
                +( a[RE22]*x[IM2] + a[IM22]*x[RE2] );
}
\end{verbatim}}
and finally the main program in {\tt main.C}:
{\scriptsize
\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include "matvec.h"
#include "defines.h"
#include <time.h>
#include "matvecmult.h"

void printTime(unsigned long start, unsigned long end, char *string)
{
        printf("%s: Start Time  %lu\n", string, start);
        printf("%s: End   Time  %lu\n", string, end);
        printf("%s: Difference  %lu cycles\n", string, end - start);

} 
  
   
int main(int argc, char *argv[]) 
{
  Matrix a;
  Vector x;
  Vector y; 
  int col,row;

  // Initialize the matrix and the vector 

  printf("Entered Program. Setting up Matrix and vector\n");

  for(row = 0; row < N_COLOUR; row++) {
    for(col = 0; col < N_COLOUR; col++) {
      a(RE,col,row) = row+1;
      a(IM,col,row) = (float)0;
      x(RE,row)   = row+1;
      x(IM,row)   = (float)0;
      y(RE,row)   = (float)0;
      y(IM,row)   = (float)0;
    }
  }

  printf("Calling Mat Vec routine \n");
  // Start timing
  unsigned long start_time, end_time;
  start_time = clock();

  // Call to matrix multiplication routine:
  // 
  // y <- A x 
  // 
  matVecMult(y.data(), a.data(), x.data());

  // Stop timing
  end_time = clock();
  
  printf("Done. Printing Results\n");

  // Print out result 
  for(row = 0; row < N_COLOUR; row++) {
    printf("[ ( %6f, %6f ) ] \n", y(RE, row), y(IM, row));
  }
  printTime(start_time, end_time, "matVecMult ");
}
\end{verbatim}}

The {\tt clock()} function can be used to time the performance of the 
routine. You should be able to find this code in {\tt /qcdsp/sfw/qos.5.3.3/example/optimise1} with a suitable makefile and linker control file.

Upon compiling and running I get the following output on the nodes
(as usual neglecting the Qdaemon messages)

\begin{verbatim}
Entered Program. Setting up Matrix and vector
Calling Mat Vec routine 
Done. Printing Results
[ ( 6.000000, 0.000000 ) ] 
[ ( 12.000000, 0.000000 ) ] 
[ ( 18.000000, 0.000000 ) ] 
matVecMult : Start Time  113454
matVecMult : End   Time  113964
matVecMult : Difference  510 cycles
\end{verbatim}

The matrix multiply routine as written, performs 66 floating point
operations during execution. Currently this takes 512 ticks of the 
(is it a 25 or 50MHz clock Bob?) clock.

\section{Step 2: Relocate C++ to CRAM}
Our first optimisation is to relocate the matrix vector multiplication
to CRAM. We have described all the steps needed to do this and have
shown the complete linker control file in section \ref{s:ModLCF}. 
We now show the whole main program:
{\scriptsize
\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include "defines.h"
#include "matvec.h"
#include <time.h>
#include "matvecmult.h"

// ------------------------------------------------
// Entry points defined by the linker control file
//
// To all intents and purposes these look like entry
// pointers to functions
// ------------------------------------------------

extern "C" void mvmult_end();
extern "C" void mvmult_begin();
extern "C" void mvmult_dest();

void loadMatVecMultIntoCRAM(void)
{
   unsigned int length = (unsigned int*)&mvmult_end
                        -(unsigned int*)&mvmult_begin;
   unsigned int * uip_src = (unsigned int *)&mvmult_begin;
   unsigned int * uip_dest = (unsigned int *)&mvmult_dest;

   printf("Copying MatVecMult Into CRAM\n");
   int i;
   for(i=0; i < length; i++) {
        *uip_dest++ = *uip_src++;
   }   
   printf("Done\n");
}

void printTime(unsigned long start, unsigned long end, char *string)
{
        printf("%s: Start Time  %lu\n", string, start);
        printf("%s: End   Time  %lu\n", string, end);
        printf("%s: Difference  %lu cycles\n", string, end - start);

}

int main(int argc, char *argv[])
{
  Matrix a;
  Vector x;
  Vector y;

  int col,row;

  // Initialize the matrix and the vector

  printf("Entered Program. Setting up Matrix and vector\n");

  for(row = 0; row < N_COLOUR; row++) {
    for(col = 0; col < N_COLOUR; col++) {
      a(RE,col,row) = row+1;
      a(IM,col,row) = (float)0;
      x(RE,row)   = row+1;
      x(IM,row)   = (float)0;
      y(RE,row)   = (float)0;
      y(IM,row)   = (float)0;
    }
  }

  loadMatVecMultIntoCRAM();

  printf("Calling Mat Vec routine \n");

  // Start timing
  unsigned long start_time, end_time;
  start_time = clock();

  // Call to matrix multiplication routine:
  //
  // y <- A x
  //

  matVecMult(y.data(), a.data(), x.data());

  // Stop timing
  end_time = clock();
 
  printf("Done. Printing Results\n");

  // Print out result
  for(row = 0; row < N_COLOUR; row++) {
    printf("[ ( %6f, %6f ) ] \n", y(RE, row), y(IM, row));
  }
  printTime(start_time, end_time, "matVecMult ");
}
\end{verbatim}}

Upon running I find that the program the output is
\begin{verbatim}
Entered Program. Setting up Matrix and vector
Copying MatVecMult Into CRAM
Done
Calling Mat Vec routine 
Done. Printing Results
[ ( 6.000000, 0.000000 ) ] 
[ ( 12.000000, 0.000000 ) ] 
[ ( 18.000000, 0.000000 ) ] 
matVecMult : Start Time  240616
matVecMult : End   Time  240922
matVecMult : Difference  306 cycles
\end{verbatim}

Hence we have managed to make a substantial gain in execution time
simply by relocating the C++ code to CRAM.

\section{Step 3: Assembler optimisation}
In this final step, we use a wrapper function
that calls an assembler routine to perform the matrix multiplication.
Since we are not interested in measuring overheads of relocating 
memory to CRAM just now, this means moving the timing tests into the 
wrapper. All the code including makefiles and routines shall eventually
be available from {\tt /qcdsp/sfw/qos.5.3.3/example/optimise3}.

\subsection{Assembling the Assembler Routine}
We have not yet had occasion to use the assembler. The assembler in 
general use (in the default Makefiles etc) is the Texas Instruments
assembler, known as {\tt asm30}. This produces Texas Instruments
({\tt .obj}) files. To be able to link these using the {\tt tcpp}
command we must prefix the files with the {\tt -fi} option to indicate
that they are in the Texas instruments COFF object format.

I defined the assembler to be used and the respective flags (having blatantly
stolen them from the default makefiles) using the following macros:
\begin{verbatim}
ASM             = asm30
ASMFLAGS        = -q -lxs -mb -v30
\end{verbatim}
and used the following rules to allow assembly:
{ \scriptsize
\begin{verbatim}
.SUFFIXES: .C .asm .tof .obj

.asm.obj:
        $(ASM) $(ASMFLAGS) $<
\end{verbatim} }

and the lines that do the linking look like:
{\scriptsize
\begin{verbatim}
ASMSRCS         = mtv.asm
ASM_OBJS        = $(ASMSRCS:.asm=.obj)
$(OUTBASE).out: $(TOF_OBJS) $(ASM_OBJS) $(INCLUDE) $(MAKEFILE) 
        $(TCPP) $(TCPPFLAGS) -e $(OUTBASE).outtof $(TOF_OBJS) -fi $(ASM_OBJS)
                $(SYSLIB) -fl $(LCF)
        t2c $(OUTBASE).outtof $(OUTBASE).out
\end{verbatim} }

\subsection{The assembler routine}
The assembler routine is shown below. Most of the contents are explained
in the comments. We make the point that the symbol {\tt ||} indicates that
the statements before and after the symbol are to be executed in parallel.
This feature is used when loading data from DRAM to CRAM and vice versa,
as well as in instructions where an addition and multiplication can 
be overlapped using the separate addition and multiplication feature
of the DSP.

{\scriptsize
\begin{verbatim}
************************************************************************
*       mtv.asm
*       Balint Joo May/2000
*
*       derived from mtv.asm written by RDM
*
*           derived from dirac.asm, written by Dong Chen.
*
*       mtv( (FLOAT *) U, (FLOAT **)x )
*
************************************************************************

Y       .set            AR0
U       .set            AR1
X       .set            AR2
FP      .set            AR3

        .def    _mtv
        .def    _cram_vector

*  Space to hold 2 vectors in CRAM

_cram_vector
        .space  12

******************************************************
* FUNCTION DEF : _mtv
******************************************************

_mtv:
        PUSH    FP
        LDI     SP,FP
******************************************************
        ; *-FP(1)       return_addr
        ; *-FP(2)       U
        ; *-FP(3)       x
        ;
        ; AR5           _address of cram_vector
******************************************************
        PUSH    R4
        PUSH    R5
        PUSHF   R6
        PUSHF   R7
        PUSH    AR4
        PUSH    AR5
        PUSH    AR6
        PUSH    AR7


******************************************************
*  Load data to CRAM

        LDI     *-FP(3), AR4            ; load x into AR4
        LDI     80h, AR5                ; get 800000 into AR5 
        LSH     16, AR5
        OR      _cram_vector, AR5       ; mask in lower bits AR5
                                        ; now holds address of _cram_vector

        LDI     AR5, AR1                ; put _cram_vector address into AR1
        LDI     *AR4++, AR0             ; dereference x into AR0
        LDF     *AR0++, R0              ; get first element *x[0] into R0

        RPTS    4                       ; repeat 5 times
        LDF     *AR0++, R0              ; get next element *x[i] into R0
     || STF     R0, *AR1++              ; store *x[i] to _cram_vector[i]

        STF     R0, *AR1++              ; store last element *x[n-1] in 
                                        ; CRAM
*  Set pointers for U, Y and X.  AR4 is loaded into Y before each
*  multiply.

        LDI     *-FP(2), U              ; set U to point to matrix
        LDI     AR5, X                  ; set X to point to _cram_buffer
        LDI     6, AR4                  ; put 6 into AR4
        ADDI    AR5, AR4                ; add AR4 to _cram_buffer -> AR4
                                        ; AR4 should point to second vector
                                        ; in CRAM = address of Y

        LDI     5, IR0

******************************************************
* ASM FUNCTION DEF : u_dot_x
******************************************************
u_dot_x:
*
* X2 = U . X1   (Complex 3x3 matrix dot 3 vector)
* 
* Y : X2                return with X2
* U : U  - 1            return with U + 17
* X : X1                return with X1
* R0,R1,R2,R3   are used for parallel instructions
* R0,R1 : temporary storage
* R2  : real part of X2
* R3  : imaginary part of X2
*
* first row of U
        LDI     AR4, Y                  ; set Y to AR4

        MPYF3   *U,     *X,     R2      ;R2 = U[0] * X1[0]
        MPYF3   *U++,   *++X,   R3      ;R3 = U[0] * X1[1]
        MPYF3   *U,     *X,     R0      ;R0 = U[1] * X1[1]
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[1] * X1[0] || R2 -= R0
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[2] * X1[2] || R3 += R1
        MPYF3   *U++, *++X,     R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[2] * X1[3] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[3] * X1[3] || R3 += R1
        MPYF3   *U++,   *-X,    R1
   ||  	SUBF3   R0,     R2,     R2      ;R1 = U[3] * X1[2] || R2 -= R0
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[4] * X1[4] || R3 += R1
        MPYF3   *U++, *++X,     R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[4] * X1[5] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[5] * X1[5] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[5] * X1[4] || R2 -= R0
* second row of U
        MPYF3   *U,     *--X(IR0),R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[6] * X1[0] || R3 += R1

        LDF     *++X,   R2
    ||  STF     R2,     *Y++            ;R2 = X1[1]        || X2[0] = R2

        MPYF3   *U++,   R2,     R3
    ||  STF     R3,     *Y++            ;R3 = U[6] * X1[1] || X2[1] = R3

        MPYF3   *U,     *X,     R2      ;R2 = U[7] * X1[1] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R2,     R0,     R2      ;R1 = U[7] * X1[0] || R2 = R0-R2
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[8] * X1[2] || R3 += R1
        MPYF3   *U++, *++X,     R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[8] * X1[3] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[9] * X1[3] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[9] * X1[2] || R2 -= R0
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[10] * X1[4] || R3 += R1
        MPYF3   *U++,   *++X,   R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[10] * X1[5] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[11] * X1[5] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[11] * X1[4] || R2 -= R0
* third row of U
        MPYF3   *U,     *--X(IR0), R0

    ||  ADDF3   R1,     R3,     R3      ;R0 = U[12] * X1[0] || R3 += R1

        LDF     *++X,   R2              ;
    ||  STF     R2,     *Y++            ;R2 = X1[1]         || X2[2] = R2

        MPYF3   *U++,   R2,     R3
    ||  STF     R3,     *Y++            ;R3 = U[12] * X1[1] || X2[3] = R3

        MPYF3   *U,     *X,     R2      ;R2 = U[13] * X1[1] || R3 += R1
        MPYF3   *U++,  *-X,     R1
    ||  SUBF3   R2,     R0,     R2      ;R1 = U[13] * X1[0] || R2 = R0-R2
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[14] * X1[2] || R3 += R1
        MPYF3   *U++,   *++X,   R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[14] * X1[3] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[15] * X1[3] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[15] * X1[2] || R2 -= R0
        MPYF3   *U,     *++X,   R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[16] * X1[4] || R3 += R1
        MPYF3   *U++,   *++X,   R1
    ||  ADDF3   R0,     R2,     R2      ;R1 = U[16] * X1[5] || R2 += R0
        MPYF3   *U,     *X,     R0
    ||  ADDF3   R1,     R3,     R3      ;R0 = U[17] * X1[5] || R3 += R1
        MPYF3   *U++,   *-X,    R1
    ||  SUBF3   R0,     R2,     R2      ;R1 = U[17] * X1[4] || R2 -= R0
        MPYF3   *X++, R0,       R0      ; dummy multiply
    ||  STF     R2,     *Y++            ;X2[4] = R2

        ADDF3   R1,     R3, R3          ;R3 += R1

        STF     R3,     *Y++            ;X2[5] = R3

*  Copy result back to DRAM
        LDI     AR4, AR0                ;  Y in CRAM
        LDI     *-FP(3), AR4
        LDI     *++AR4, AR1             ;  Y in DRAM
        
        LDF     *AR0++,R0               ; get first element of Y into R0
        RPTS    4                       ; repeat 5 times
        LDF     *AR0++, R0              ; get next element of Y into R0
     || STF     R0, *AR1++              ; store previous element to DRAM
        STF     R0, *AR1++              ; store last element
        POP     AR7                     ; restore registers and stack frame
        POP     AR6
        POP     AR5
        POP     AR4
        POPF    R7
        POPF    R6
        POP     R5
        POP     R4
        POP     FP
        RETS
\end{verbatim} }

By my counting this routine performs the multiplication using 73 floating
point instructions, however a lot of these are executed in parallel. Also
the routine was originally written to be performing 8 SU(3) multiplies
in a similar manner to a 4D finite difference operator. I may not have
stripped out all vestiges of this properly. However the routine does
seem to work. It is called from {\bf main.C} in a similar manner to the 
last section. We list the complete {\bf main.C} file below:
{\scriptsize
\begin{verbatim}
#include <stdio.h>
#include <stdlib.h>
#include "defines.h"
#include "matvec.h"
#include <time.h>

// ------------------------------------------------
// Entry points defined by the linker control file
//
// To all intents and purposes these look like entry
// pointers to functions
// ------------------------------------------------
extern "C" void mvmult_end();
extern "C" void mvmult_begin();
extern "C" void mvmult_dest();

// -------------------------------------------------
// Entry point of Matrix Vector assembler routine
// -------------------------------------------------
extern "C" void mtv(float *u, float **vecs);


// -----------------------------------------------
// Routine for loading assembler routine MTV
// into CRAM
// -----------------------------------------------
void loadMatVecMultIntoCRAM(void)
{
  unsigned int length = (unsigned int*)&mvmult_end
                         -(unsigned int*)&mvmult_begin;

  unsigned int * uip_src = (unsigned int *)&mvmult_begin;
  unsigned int * uip_dest = (unsigned int *)&mvmult_dest;

  printf("Copying MatVecMult Into CRAM\n");
  int i;
  for(i=0; i < length; i++) {
    *uip_dest++ = *uip_src++;
  }
  printf("Done\n");
}

void printTime(unsigned long start, unsigned long end, char *string){
        printf("%s: Start Time  %lu\n", string, start);
        printf("%s: End   Time  %lu\n", string, end);
        printf("%s: Difference  %lu cycles\n", string, end - start);
} 


// ---------------------------------------------
// Wrapper Routine to Call Assembler routine mtv
// 
// Does y = Ax
// ---------------------------------------------
void matVecMultMtv(float *y, float *A, float *x)
{


  // -------------------------------
  // mtv expects a (float **)vectors
  // so that vectors[0] = x
  // and vectors[1] = y
  // -------------------------------
  float *vector_array[2];
  float **vectors = &vector_array[0];;
  vector_array[0]=x;
  vector_array[1]=y;

  // -------------------------------
  // Start Timing
  // -------------------------------
  unsigned long start_time, end_time;
  start_time = clock();

  // -------------------------------
  // Call assembler
  // -------------------------------
  mtv(A, vectors);  

  // -------------------------------
  // End Timing
  // -------------------------------
  end_time = clock();
  printTime(start_time,end_time, "MTV Assembler");
}

int main(int argc, char *argv[])
{
  int col,row;
  Vector x,y;
  Matrix A;

  // ------------------------------------
  // Initialize the matrix and the vector
  // ------------------------------------
  printf("Setting up Matrix and vector\n");
  for(row = 0; row < N_COLOUR; row++) {
    for(col = 0; col < N_COLOUR; col++) {
      A(RE,col,row) = row+1;
      A(IM,col,row) = (float)0;
      x(RE,row)   = row+1;
      x(IM,row)   = (float)0;
      y(RE,row)   = (float)0;
      y(IM,row)   = (float)0;
    }
  }
  // -----------------------------
  // Load MatVec routine into CRAM
  // -----------------------------
  printf("Loading Matrix Vector Routine into CRAM\n");
  loadMatVecMultIntoCRAM();


  // --------------------------------------
  // Call to matrix multiplication routine:
  //
  // y <- A x
  // --------------------------------------
  printf("Calling Mat Vec routine \n");
  matVecMultMtv(y.data(), A.data(), x.data());

  // --------------------------------------
  // Print out result
  // --------------------------------------
  for(row = 0; row < N_COLOUR; row++) {
    printf("[ ( %6f, %6f ) ] \n", y(RE, row), y(IM, row));
  }
}
\end{verbatim}}

You can find all this code in {\tt /qcdsp/sfw/qos5.3.3/example/optimise3}.
On running I get the following output:
\begin{verbatim}
Setting up Matrix and vector
Loading Matrix Vector Routine into CRAM
Copying MatVecMult Into CRAM
Done
Calling Mat Vec routine 
MTV Assembler: Start Time  303414
MTV Assembler: End   Time  303587
MTV Assembler: Difference  173 cycles
[ ( 6.000000, 0.000000 ) ] 
[ ( 12.000000, 0.000000 ) ] 
[ ( 18.000000, 0.000000 ) ] 
\end{verbatim}

\section{Summary}
In this chapter we have reviewed the basic means of performing 
single procesor optimisations on the QCDSP. These can be made
by making use of the 2Kword on chip RAM and the circular buffer.

The circuler buffer is considered as an advanced topic and is left
for future addenda/revisions of this document. We have then detailed
the use of the CRAM and presented a three stage process to optimisation:
\begin{enumerate}
\item{Step 1\ } Write the code as usual
\item{Step 2\ } Relocate compute intensive (C++) routine to CRAM
\item{Step 3\ } Replace compute intensive routine in CRAM with
\end{enumerate}
assembler routine taking advantage of the ability to execute two 
instructions per cycle.

\subsection{Overlay Summary}
When defining an overlay, define its origin in the {\tt allocate} statement
of the linker control file to be in the CRAM. It is useful to define
a compiler symbol for this origin. Since one is now  dealing with 
virtual addresses that are different from physical addresses, one must
include a {\tt physical} statement at the end of the linker control file
to specify the layout of sections. Here it is possible to define
symbols pointing to the start and end of the overlay which will facilitate
its copying to the CRAM.

Overlay code is module based. A module unit is a {\bf .toff} or a {\tt .coff}
file. Alternatively an archive {\bf .olb} file can contain a collection of 
modules. Hence code for different overlays must reside in different files.

Overlays must be explicitly copied to CRAM before used. 

\subsection{Linker symbols and C++ Files}
Linker symbols  can be made visible to C++
program files through the use of the {\tt extern "C" void symbol()} statements,
This stops the compiler from encoding {\tt symbol}. Linker symbols need
to be defined with a leading underscore, but this underscore is dropped
when dealing with them in C++ files.

\subsection{Assembly Summary}
Assembly coded  overlays work the same way as C++ overlays, except that the 
object files are assembled using the {\tt asm30} assembler rather than 
compiled. The {\tt asm30} assembler outputs object files in the Texas Intsruments COFF format ({\tt .obj} suffix). Such files should automatically be
recognised by {\tt tcpp} and dealt with appropriately. One may however
at one's discretion prepend them with {\tt -fi} flag which forces {\tt tcpp} 
to treat them as COFF object files.



